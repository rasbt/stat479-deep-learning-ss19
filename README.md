# STAT479: Deep Learning (Spring 2019)

**Instructor: Sebastian Raschka**

Lecture material for the STAT 479 Deep Learning course at University Wisconsin-Madison. For details, please see the course website at http://pages.stat.wisc.edu/~sraschka/teaching/stat479-ss2019/


## Course Calendar

Please see [http://pages.stat.wisc.edu/~sraschka/teaching/stat479-ss2019/#calendar](http://pages.stat.wisc.edu/~sraschka/teaching/stat479-ss2019/#calendar).

## Topic Outline

- History of neural networks and what makes deep learning different from “classic machine learning”
- Introduction to the concept of neural networks by connecting it to familiar concepts such as logistic regression and multinomial logistic regression (which can be seen as special cases: single-layer neural nets)
- Modeling and deriving non-convex loss function through computation graphs
- Introduction to automatic differentiation and PyTorch for efficient data manipulation using GPUs
- Convolutional neural networks for image analysis
- 1D convolutions for sequence analysis
- Sequence analysis with recurrent neural networks
- Generative models to sample from input distributions
  - Autoencoders
  - Variational autoencoders
  - Generative Adversarial Networks


## Material

- **L01: What are Machine Learning and Deep Learning? An Overview.** [[Slides](L01-intro/L01-intro_slides.pdf)]
- **L02: A Brief Summary of the History of Neural Networks and Deep Learning.** [[Slides](L02_dl-history/L02_dl-history_slides.pdf)]
- **L03: The Perceptron.** [[Slides](L03_perceptron/L03_perceptron_slides.pdf)] [[Code](L03_perceptron/code)]
- **L04: Linear Algebra for Deep Learning.** [[Slides](L04_linalg-dl/L04_linalg-dl_slides.pdf)]
- **L05: Fitting Neurons with Gradient Descent.** [[Slides](L05_grad-descent/L05_gradient-descent_slides.pdf)]  [[Code](L05_grad-descent/code)]
- **L06: Automatic Differentiation with PyTorch.** [[Slides](L06_pytorch/L06_pytorch_slides.pdf)]  [[Code](L06_pytorch/code)]
- **L07: Cloud Computing.** [[Slides](L07_cloud-computing/L07_cloud-computing_slides.pdf)] 
- **L08: Logistic Regression and Multi-class Classification** [[Slides](L08_logistic/L08_logistic_slides.pdf)] [[Code](L08_logistic/code)] 
- **L09: Multilayer Perceptrons** [[Slides](L09_mlp/L09_mlp_slides.pdf)]  [[Code](L09_mlp/code)] 
- **L10: Regularization** [[Slides](L10_regularization/L10_regularization_slides.pdf)]  [[Code](L10_regularization/code)] 
- **L11: Normalization and Weight Initialization** [[Slides](L11_weight-init/L11_weight-init_slides.pdf)] 
- **L12: Learning Rates and Optimization Algorithms** [[Slides](L12_optim/L12_optim_slides.pdf)] 
- **L13: Introduction to Convolutional Neural Networks** [[Slides (part 1)](L13_intro-cnn/L13_intro-cnn-part1_slides.pdf)] [[Slides (part 2)](L13_intro-cnn/L13_intro-cnn-part2_slides.pdf)]  [[Slides (part 3)](L13_intro-cnn/L13_intro-cnn-part3_slides.pdf)] 
- **L14: Introduction to Recurrent Neural Networks** [[Slides (part 1)](L14_intro-rnn/L14_intro-rnn-part1_slides.pdf) [Slides (part 2)](L14_intro-rnn/L14_intro-rnn-part2_slides.pdf)] 
- **L15: Introduction to Autoencoders** [[Slides](L15_autoencoder/L15_autoencoder_slides.pdf)] [[Code](L15_autoencoder/code)]
- **L16: Variational Autoencoders** (skipped due to timing constraints)
- **L17: Generative Adversarial Networks** [[Slides](L17_gans/L17_gan_slides.pdf)] [[Code](L17_gans/code)]
